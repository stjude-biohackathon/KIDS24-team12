{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba14fae-95cf-4ba7-8097-eb9add14c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API docs\n",
    "# - https://platform.openai.com/docs/api-reference\n",
    "# file_search:\n",
    "# - https://platform.openai.com/docs/assistants/tools/file-search?context=without-streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2913f51-cd26-4c6b-b3ca-893a49fd0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.conda/envs/py38/bin/python\n",
      "~/.conda/envs/py38/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4c42c0-a0af-4b8e-a944-7857b5a01b9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Commented out to be able to `Run All Cells` smoothly.\n",
    "\n",
    "#!pip install PyPDF2\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a978e2-7caf-4218-bedf-ae276b87a46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:52:49) \n",
      "[GCC 13.3.0]\n",
      "1.56.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import openai\n",
    "\n",
    "print(sys.version)\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1935a19b-2768-409f-8eba-b08e07093831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"oai_token.txt\", 'r') as file:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = file.readline().strip()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f014ac6-373c-4738-a76c-de52faf593f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 740\n"
     ]
    }
   ],
   "source": [
    "pdf_document_filepath = \"files/4-2_manual.pdf\"\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Load the PDF file\n",
    "reader = PdfReader(pdf_document_filepath)\n",
    "\n",
    "# Get the number of pages\n",
    "NUM_PAGES = len(reader.pages)\n",
    "print(f\"Number of pages: {NUM_PAGES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b7d251-5348-459f-828c-4ca9f8e7213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "# pages is a 0-indexed array\n",
    "def extract_pages(input_pdf, output_pdf, pages):\n",
    "    reader = PdfReader(input_pdf)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    for page_num in pages:\n",
    "        writer.add_page(reader.pages[page_num])\n",
    "\n",
    "    with open(output_pdf, 'wb') as output_file:\n",
    "        writer.write(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1c39bf-f889-4c01-85da-b03cf79a20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    " \n",
    "client = OpenAI()\n",
    " \n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"DRAGEN Assistant\",\n",
    "  instructions=\"You are an expert reader of manual pages, which include text, tables, and images. Use the documents provided to you to answer questions about what the manual says. You must stick to the manual and not complement your responses with any information not included in the manual pages provided.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "assistant_id = assistant.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4558b5d-55e4-48f9-9d58-79d6fb17eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Start a thread with a message containing a file.\n",
    "async def create_thread_with_message(filepath, message, prev_filepath=None):\n",
    "    client = AsyncOpenAI()\n",
    "    messages=[{\"role\": \"user\",\"content\": message,\"attachments\": []}]\n",
    "\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        # Upload the file\n",
    "        message_file = await client.files.create(\n",
    "            file=file, purpose=\"assistants\"\n",
    "        )\n",
    "        # Attach the new file to the message.\n",
    "        messages[0][\"attachments\"].append(\n",
    "            {\n",
    "                \"file_id\": message_file.id, \n",
    "                \"tools\": [{\"type\": \"file_search\"}]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Handle prev page\n",
    "    if prev_filepath:\n",
    "        with open(prev_filepath, \"rb\") as prev:\n",
    "            # Upload the file\n",
    "            prev_message_file = await client.files.create(\n",
    "                file=prev, purpose=\"assistants\"\n",
    "            )\n",
    "            # Attach the new file to the message.\n",
    "            messages[0][\"attachments\"].append(\n",
    "                {\n",
    "                    \"file_id\": prev_message_file.id, \n",
    "                    \"tools\": [{\"type\": \"file_search\"}]\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    # Create a thread and attach the files to the message\n",
    "    thread = await client.beta.threads.create(messages=messages)\n",
    "    \n",
    "    thread_id = thread.id \n",
    "    #file_id = message_file.id\n",
    "    #vector_store_id = thread.tool_resources.file_search.vector_store_ids[0]\n",
    "    #prev_vector_store_id = prev_vector_store.id\n",
    "    return thread_id #, file_id, vector_store_id, prev_vector_store_id\n",
    "\n",
    "# Use the create-and-poll SDK helper to create a run and poll its status\n",
    "# until it's in a terminal state.\n",
    "async def create_and_submit_run(thread_id):\n",
    "    client = AsyncOpenAI()\n",
    "    run = await client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread_id, assistant_id=assistant_id\n",
    "    )\n",
    "    \n",
    "    messages = []\n",
    "    async for message in client.beta.threads.messages.list(thread_id=thread_id, run_id=run.id):\n",
    "        messages.append(message)\n",
    "    return messages\n",
    "\n",
    "def extract_response(messages):    \n",
    "    message_content = messages[0].content[0].text\n",
    "    annotations = message_content.annotations\n",
    "    citations = []\n",
    "    for index, annotation in enumerate(annotations):\n",
    "        message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "        if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "            cited_file = client.files.retrieve(file_citation.file_id)\n",
    "            citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "    \n",
    "    response = message_content.value\n",
    "    references = \"\\n\".join(citations)\n",
    "\n",
    "    return response, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31b74ea4-cefb-4ea9-b212-286b227b4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"You are a document processing assistant tasked with generating prompts based on the content of a manual page. \n",
    "You are being provided with two pages: the current manual page and the preceding page for context. Focus primarily on the current page. Refer to the preceding page only when necessary to ensure continuity for sections or information that began earlier. The page number is located on the lower right corner of every page.\n",
    "\n",
    "Follow these instructions carefully:\n",
    "1. Analyze the current page from the manual for relevant information, including text, tables, diagrams, and examples. Relevant information refers to useful information for someone who is trying to learn how to use this platform. \n",
    "2. Generate between 10 and 20 detailed Alpaca-format prompts based on the relevance and length of the current (not the preceding) page.\n",
    "3. Ensure that the response is formatted in the Alpaca structure, which is a JSON array of objects. Each object represents a single prompt and contains the following fields:\n",
    "instruction: The task or query for the model (required).\n",
    "input: Any context or details relevant to the instruction (optional).\n",
    "output: The model's expected response (required).\n",
    "system: The system instruction, which should always be \"Do not add information not explicitly stated or speculate.\".\n",
    "history: A list of relevant prior [instruction, response] pairs, representing conversational history (optional).\n",
    "Each field should be enclosed in quotation marks, separated by commas, and formatted as valid JSON. Multiple prompts should be enclosed in square brackets [] to form an array.\n",
    "4. Include exactly one prompt that explicitly states the current page number as the source of the information being discussed.\n",
    "5. If the page includes examples or diagrams, generate prompts that specifically cover those examples and diagrams.\n",
    "6. Some pages may contain information that continues from a previous page. If this is the case, refer to the previous page to ensure the prompts comprehensively address the complete context of the information.\n",
    "7. Include all important details from the page in the prompts. The prompts do not have to be concise but must be thorough, comprehensive, and factual.\n",
    "8. Do not wrap your response in a type label such as ```json```\n",
    "\n",
    "Use these guidelines to process the provided page and return the output in valid Alpaca format. Only return the prompts, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb86baa4-2cda-4e89-aab8-16b2d12fe653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "from collections import deque\n",
    "\n",
    "# main coroutine\n",
    "async def event_loop(pages_to_process):\n",
    "    prev_filepath = None\n",
    "    # for cleaning up later\n",
    "    tasks = {}\n",
    "    thread_ids = deque([])\n",
    "    pages = deque([])\n",
    "    for page in pages_to_process:\n",
    "        print(f\"\\tProcessing page {page}\")\n",
    "                \n",
    "        if page > 6: # page 6 is the first content page\n",
    "            prev_filepath = f\"files/page_{page-1}.pdf\"\n",
    "            if not os.path.exists(prev_filepath):\n",
    "                extract_pages(pdf_document_filepath, prev_filepath, [page-1])\n",
    "\n",
    "        page_filepath = f\"files/page_{page}.pdf\"\n",
    "        if not os.path.exists(page_filepath):\n",
    "            extract_pages(pdf_document_filepath, page_filepath, [page])\n",
    "        \n",
    "        thread_id = await create_thread_with_message(page_filepath, message, prev_filepath=prev_filepath)\n",
    "\n",
    "        task = create_and_submit_run(thread_id)\n",
    "        tasks[str(page)] = task\n",
    "\n",
    "        # for cleaning up later\n",
    "        thread_ids.append(thread_id)\n",
    "        pages.append(page)\n",
    "        \n",
    "    # Wait for all tasks to complete\n",
    "    raw_responses = await asyncio.gather(*tasks.values())\n",
    "    return raw_responses, tasks, thread_ids, pages\n",
    "\n",
    "def save_results(raw_responses_dict, overwrite=False):\n",
    "    stored_prompts = {}\n",
    "    with open('files/metadata.json', 'r') as metadata:\n",
    "        stored_prompts = json.load(metadata)\n",
    "    \n",
    "    new_prompts = {}\n",
    "    for page, raw_response in raw_responses_dict.items():\n",
    "        if page not in stored_prompts or overwrite:\n",
    "            new_prompts[page] = extract_response(raw_response)[0]            \n",
    "    \n",
    "    stored_prompts.update(new_prompts)\n",
    "    \n",
    "    with open('files/metadata.json', 'w') as metadata:\n",
    "        json.dump(stored_prompts, metadata, indent=4)  # 'indent=4' makes the JSON file pretty-printed\n",
    "\n",
    "# to clean up threads and tasks\n",
    "async def clean_up(tasks, thread_ids, pages):\n",
    "    client = AsyncOpenAI()\n",
    "    while thread_ids:\n",
    "        t_id = thread_ids.popleft()\n",
    "        try:\n",
    "            await client.beta.threads.delete(t_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Cleaning up threads failed: {e}\")\n",
    "\n",
    "    # Not necessary unless global\n",
    "    #while pages:\n",
    "    #    p = pages.popleft()\n",
    "    #    del(tasks[p])\n",
    "\n",
    "async def submitter(pages_to_process, overwrite=False):\n",
    "    raw_responses, tasks, thread_ids, pages_processed = await event_loop(pages_to_process)\n",
    "\n",
    "    raw_responses_dict = {page: response for page, response in zip(tasks.keys(), raw_responses)}\n",
    "    save_results(raw_responses_dict, overwrite)\n",
    "    \n",
    "    await clean_up(tasks, thread_ids, pages_processed)    \n",
    "\n",
    "    return pages_processed\n",
    "\n",
    "async def driver(pages_to_process=[]): # first 6 pages and last page are non-content\n",
    "    if pages_to_process:\n",
    "        await submitter(pages_to_process, True)\n",
    "    else:\n",
    "        stored_prompts = {}\n",
    "        with open('files/metadata.json', 'r') as metadata:\n",
    "            stored_prompts = json.load(metadata)\n",
    "    \n",
    "        for page in range(6, NUM_PAGES-1, 10): \n",
    "            if str(page) in stored_prompts:\n",
    "                continue\n",
    "\n",
    "            # batching calls to event_loop for fault tolerance\n",
    "            [pages_to_process.append(p) for p in range(page, page+10)]\n",
    "            if pages_to_process[-1] >= NUM_PAGES-1:\n",
    "                break\n",
    "                \n",
    "            pages_processed = await submitter(pages_to_process)\n",
    "            # for check at start of the loop, since event_loop process more than 1 page at a time\n",
    "            for page in pages_processed:\n",
    "                stored_prompts[str(page)] = None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fe27c9f-f10e-451b-ab22-ef23d7859f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reprocess failed responses\n",
    "def reprocess_failed():\n",
    "    stored_prompts = {}\n",
    "    with open('files/metadata.json', 'r') as metadata:\n",
    "        stored_prompts = json.load(metadata)\n",
    "    \n",
    "    pages_to_reprocess = []\n",
    "    for page, prompt_arr in stored_prompts.items():\n",
    "        if isinstance(prompt_arr, str):\n",
    "            try:\n",
    "                isinstance(json.loads(prompt_arr), list)\n",
    "            except Exception:\n",
    "                #print(f\"Will reprocess page {page}\")\n",
    "                #print(prompt_arr)\n",
    "                pages_to_reprocess.append(int(page))\n",
    "        else:\n",
    "            print(f\"ERROR: value not stored as a string but a: {type(prompt_arr)}.\")\n",
    "\n",
    "    return pages_to_reprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e24a42f-091a-46c3-b8a9-1681bbc0e3cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell driving main logic\n",
    "\n",
    "await driver()\n",
    "failed = reprocess_failed()\n",
    "while failed:\n",
    "    await driver(failed)\n",
    "    failed = reprocess_failed()\n",
    "    print(f\"reprocessing {failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74103953-ed5b-40e1-8e53-f9db8d4fb190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finalize data for fine-tuning step in next notebook\n",
    "stored_prompts = {}\n",
    "with open('files/metadata.json', 'r') as file:\n",
    "    stored_prompts = json.load(file)\n",
    "\n",
    "all_prompts = []\n",
    "for arr in stored_prompts.values():\n",
    "    # Ensure each value is parsed into a Python object\n",
    "    if isinstance(arr, str):  # If `arr` is still a JSON string\n",
    "        #print(arr)\n",
    "        arr = json.loads(arr)\n",
    "    all_prompts.extend(arr)  # Use `extend` for nested lists\n",
    "\n",
    "#print(all_prompts[:10])\n",
    "\n",
    "with open('files/dataset.json', 'w') as file:\n",
    "    json.dump(all_prompts, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99080e2-4b64-40c3-a49d-77279a5c77b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files with purpose 'assistants' have been deleted.\n",
      "All returned vector stores have been deleted\n"
     ]
    }
   ],
   "source": [
    "# cleaning up\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.files.list(purpose=\"assistants\")\n",
    "for file in response.data:\n",
    "    client.files.delete(file.id)\n",
    "print(\"All files with purpose 'assistants' have been deleted.\")\n",
    "\n",
    "#retries = 0\n",
    "#while retries < 15:\n",
    "try:\n",
    "    vector_stores = client.beta.vector_stores.list()\n",
    "    #retries = 0\n",
    "    for vs in vector_stores:\n",
    "        try:\n",
    "            client.beta.vector_stores.delete(vs.id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting vector store: {vs}\")\n",
    "    print(\"All returned vector stores have been deleted\")\n",
    "except:\n",
    "    print(\"there was an issue, retrying...\")\n",
    "    #retries += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1514307-7470-4794-969e-930646030188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code graveyard\n",
    "#    ### Handle prev page ###\n",
    "#    page_num = int(filepath.strip(\"files/page_.pdf\"))\n",
    "#    # Create a vector store to contain the preceding manual page.\n",
    "#   if page_num > 0:\n",
    "#        prev_vector_store = await client.beta.vector_stores.create(name=\"Preceding manual page\")\n",
    "#\n",
    "#        file_paths = [f\"files/page_{page_num-1}.pdf\"]\n",
    "#        file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "#        file_batch = await client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "#          vector_store_id=prev_vector_store.id, files=file_streams\n",
    "#        )\n",
    "#        if file_batch.status != \"completed\":\n",
    "#            print(f\"Upload failed for preceding file: {file_path}.\")\n",
    "#\n",
    "#        assistant = await client.beta.assistants.update(\n",
    "#          assistant_id=assistant_id,\n",
    "#          tool_resources={\"file_search\": {\"vector_store_ids\": [prev_vector_store.id]}},\n",
    "#        )\n",
    "#    ### End handle prev page ###\n",
    "\n",
    "\n",
    "#    - IMPORTANT: If the current page is a non-content page (such as a title page, table of contents, blank page, etc.) do not generate any prompts. Instead, return an empty response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7176a-a999-41a6-a468-8535b6584337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
